<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Task_1 lesson03(Bar chart)</title>
    <link href="/2024/04/16/Task_1%20lesson03(Bar%20graph)/"/>
    <url>/2024/04/16/Task_1%20lesson03(Bar%20graph)/</url>
    
    <content type="html"><![CDATA[<h1 id="Bar-chart"><a href="#Bar-chart" class="headerlink" title="Bar chart"></a>Bar chart</h1><ul><li><p>First, make a very general comparison. (summary&#x2F; Overview paragraph)</p></li><li><p>Second, compare the specific numbers.</p><p><img src="/img/figure/bar_chart.png" alt="Bar chart"></p></li></ul><p>·</p><h3 id="Introduction-改写"><a href="#Introduction-改写" class="headerlink" title="Introduction: 改写"></a>Introduction: 改写</h3><p>e.g. The chart below shows global sales of the top five mobile phone brands between 2009 and 2013</p><p>改写为：The bar chart &#x3D;&#x3D;compares&#x3D;&#x3D; the number of phone sold worldwide(替换global). By the five most popular manufactures in the years 2019, 2011 and 2013.</p><h3 id="Overall-：-2-sentences-2-main-points"><a href="#Overall-：-2-sentences-2-main-points" class="headerlink" title="Overall ： 2 sentences, 2 main points"></a>Overall ： 2 sentences, 2 main points</h3><p>(&#x3D;&#x3D;最高&#x3D;&#x3D;)It’s clear that Nokia sold the most mobile phones between 2009 and 2011, but Samsung became the best selling brand in 2013. (&#x3D;&#x3D;总的相同的上升趋势&#x3D;&#x3D;)Samsung and Apple saw the biggest rises in sale over a period of 4 years.</p><h3 id="Details-1-comparison-changes-over-time"><a href="#Details-1-comparison-changes-over-time" class="headerlink" title="Details_1 : comparison, changes over time."></a>Details_1 : comparison, changes over time.</h3><p>(&#x3D;&#x3D;起点&#x3D;&#x3D;)In 2019, Nokia sold close to 450 million mobile phones, which was almost &#x3D;&#x3D;double the number of&#x3D;&#x3D; handset(替换mobile phone) sold by the second most successful &#x3D;&#x3D;manufacture(指代手机生产公司)&#x3D;&#x3D;, Samsung. &#x3D;&#x3D;Over the following 4 years&#x3D;&#x3D;, however, Nokia’s sales figure fell by approximately 200 million units, whereas(然而) Samsung saw sales rise &#x3D;&#x3D;by a similar amount&#x3D;&#x3D;(上升与下降的水平相似，形成对比). By 2013, Samsung had become the &#x3D;&#x3D;market leader&#x3D;&#x3D; (换一种说法表示几者之间最高 )with sales reaching into 450 million units.</p><h3 id="Details-2-comparison-changes-over-time"><a href="#Details-2-comparison-changes-over-time" class="headerlink" title="Details_2 : comparison, changes over time."></a>Details_2 : comparison, changes over time.</h3><p>The other three top selling mobile phone bands between 2019 and 2013 were LG, ZTE and Apple. In 2019, these companies sold around 125 millions , 50 millions and 25 millions handsets &#x3D;&#x3D;respectively(分别)&#x3D;&#x3D;, but Apple overtook the other companies in 2011. In 2013, &#x3D;&#x3D;purchases(换主语)&#x3D;&#x3D; of Apple handset reached 150 million units, while LG saw &#x3D;&#x3D;decline&#x3D;&#x3D; sales and figure for ZTE &#x3D;&#x3D;rose&#x3D;&#x3D; only sightly.</p><hr><ul><li><p>sold worldwide &#x3D; global sales</p></li><li><p>most popular, best selling brand, top selling, most successful, </p></li><li><p>market leader, second  most popular manufactury</p></li><li><p>mobile phone &#x3D; handset</p></li><li><p>brands品牌 &#x3D; manufactures制造商 &#x3D; companies公司 &#x3D; vendors供应商</p></li><li><p>close to, almost, approximately, around </p></li><li><p>respectively(分别)</p></li><li><p>Areached xx(数量), while B(主语) saw xx(上升&#x2F;下降), and the figure for C(主语) xx(上升&#x2F;下降) </p><blockquote><p>e.g.In 2013, purchases(换主语) of Apple handset reached 150 million units, while LG saw decline sales and figure for ZTE rose only sightly.</p></blockquote></li><li><p>rose sightly &#x3D; have a negligible amount rose 上升缓慢</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>IELTS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>writing Task_1</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Task_1 lesson02(line graph)</title>
    <link href="/2024/04/16/Task_1%20lesson02(line%20graph)/"/>
    <url>/2024/04/16/Task_1%20lesson02(line%20graph)/</url>
    
    <content type="html"><![CDATA[<h1 id="line-graph"><a href="#line-graph" class="headerlink" title="line graph"></a>line graph</h1><ul><li>First, make a very general comparison. (summary&#x2F; Overview paragraph)</li><li>Second, compare the lines at specific points.(details paragraph)</li></ul><p><img src="/img/figure/line_graph.jpg" alt="line graph"></p><h3 id="Introduction-改写"><a href="#Introduction-改写" class="headerlink" title="Introduction: 改写"></a>Introduction: 改写</h3><p>e.g. &#x3D;&#x3D;The graph below shows&#x3D;&#x3D; electricity production(in terawatt hours) in France between 1980 and 2012.</p><p>改写为：The line graph &#x3D;&#x3D;compares&#x3D;&#x3D; &#x3D;&#x3D;the amount&#x3D;&#x3D; of electricity produced in France &#x3D;&#x3D;using four different sources&#x3D;&#x3D; of  power &#x3D;&#x3D;from&#x3D;&#x3D; 1980 &#x3D;&#x3D;to&#x3D;&#x3D; 2012(&#x3D;&#x3D;over a period of&#x3D;&#x3D; 32 years)</p><h3 id="overall-2-sentences-2-main-points"><a href="#overall-2-sentences-2-main-points" class="headerlink" title="overall: 2 sentences, 2 main points"></a>overall: 2 sentences, 2 main points</h3><p>highest&#x2F;lowest : </p><p>It’s clear that nuclear power was &#x3D;&#x3D;by far&#x3D;&#x3D; the most important &#x3D;&#x3D;means of(手段)&#x3D;&#x3D; of electricity generation over the period shown. </p><p>Renewables  provided the lowest amount of electricity amount of electricity in each years.</p><h3 id="Details-1-3-sentences"><a href="#Details-1-3-sentences" class="headerlink" title="Details_1 : 3 sentences"></a>Details_1 : 3 sentences</h3><p>(起点) In 1980, thermal power stations were the main source of electricity in France, &#x3D;&#x3D;generating&#x3D;&#x3D; around terawatt hour of the power(&#x3D;&#x3D;top&#x3D;&#x3D;). Nuclear and hydrodectric power stations produced just under 75 terawatt  hour of electricity each(&#x3D;&#x3D;second&#x2F;third&#x3D;&#x3D;), and renewables provided a negligible amount(&#x3D;&#x3D;交点&#x3D;&#x3D;). Just one year later, unclear power overtook(catch up with) thermal power as the primary source of electricity.</p><h3 id="Details-2-3-sentences"><a href="#Details-2-3-sentences" class="headerlink" title="Details_2 : 3 sentences"></a>Details_2 : 3 sentences</h3><p>(&#x3D;&#x3D;到达顶点&#x3D;&#x3D;)Between 1980 and 2005, electricity production from nuclear power rose dramatically to a peak of 430 terawatt hours.(&#x3D;&#x3D;下降&#x3D;&#x3D;)By contrast, the figure for thermal power fell to only 50 terawatt hours in 1985, and remained at this level for the rest of the period. Hydroelectric power generation &#x3D;&#x3D;remained relatively stable&#x3D;&#x3D; between 50 to 80 terawatt hours, for the whole 32-year period, but renewable electricity production saw a small rose to approximately 25 terawatt hours by 2012.</p><hr><ul><li><p>xx saw a small rose to xx by time</p></li><li><p>xx increased dramatically to a peak of xx</p></li><li><p>by contrast</p></li><li><p>the figure for &#x3D;&#x3D;&gt; the number of 相互替换，避免重复</p></li><li><p>remained at xx level, remained relatively stable相对稳定; remained at this level for the rest of the period</p></li><li><p>表时间区间：over a period of xx year(持续多少年)&#x2F; over the period shown</p></li><li><p>表示最重要: by far the most important&#x2F;highest</p></li><li><p>表示几乎没有: a negligible amount</p></li><li><p>表示xx超过xx: xx overtook xx</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>IELTS</category>
      
    </categories>
    
    
    <tags>
      
      <tag>writing Task_1</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>创建ROS工作空间</title>
    <link href="/2024/01/26/%E5%88%9B%E5%BB%BAROS%E5%B7%A5%E4%BD%9C%E7%A9%BA%E9%97%B4/"/>
    <url>/2024/01/26/%E5%88%9B%E5%BB%BAROS%E5%B7%A5%E4%BD%9C%E7%A9%BA%E9%97%B4/</url>
    
    <content type="html"><![CDATA[<h2 id="创建ROS工作空间"><a href="#创建ROS工作空间" class="headerlink" title="创建ROS工作空间"></a>创建ROS工作空间</h2><p>ROS中的程序即便使用不同的编程语言，实现流程也大致类似，以当前HelloWorld程序为例，实现流程大致如下：</p><ol><li>先创建一个工作空间；</li><li>再创建一个功能包；</li><li>编辑源文件；</li><li>编辑配置文件；</li><li>编译并执行。</li></ol><p>上述流程中，C++和Python只是在步骤3和步骤4的实现细节上存在差异，其他流程基本一致。先实现C++和Python程序编写的通用部分步骤1与步骤2</p><h4 id="1-创建工作空间并初始化"><a href="#1-创建工作空间并初始化" class="headerlink" title="1.创建工作空间并初始化"></a>1.创建工作空间并初始化</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> -p 自定义空间名称/src<br><span class="hljs-built_in">cd</span> 自定义空间名称<br>catkin_make<br></code></pre></td></tr></table></figure><p>上述命令，首先会创建一个工作空间以及一个 src 子目录，然后再进入工作空间调用 catkin_make命令编译。</p><h4 id="2-进入-src-创建-ros-包并添加依赖"><a href="#2-进入-src-创建-ros-包并添加依赖" class="headerlink" title="2.进入 src 创建 ros 包并添加依赖"></a>2.进入 src 创建 ros 包并添加依赖</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> src<br>catkin_create_pkg 自定义ROS包名 roscpp rospy std_msgs<br></code></pre></td></tr></table></figure><p>上述命令，会在工作空间下生成一个功能包，该功能包依赖于 roscpp、rospy 与 std_msgs，其中roscpp是使用C++实现的库，而rospy则是使用python实现的库，std_msgs是标准消息库，创建ROS功能包时，一般都会依赖这三个库实现。</p><hr><p><strong>注意:</strong> 在ROS中，虽然实现同一功能时，C++和Python可以互换，但是具体选择哪种语言，需要视需求而定，因为两种语言相较而言:C++运行效率高但是编码效率低，而Python则反之，基于二者互补的特点，ROS设计者分别设计了roscpp与rospy库，前者旨在成为ROS的高性能库，而后者则一般用于对性能无要求的场景，旨在提高开发效率。</p>]]></content>
    
    
    <categories>
      
      <category>tutorial</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ROS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ROS中添加自定义python脚本</title>
    <link href="/2024/01/26/ROS%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89python%E8%84%9A%E6%9C%AC/"/>
    <url>/2024/01/26/ROS%E4%B8%AD%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89python%E8%84%9A%E6%9C%AC/</url>
    
    <content type="html"><![CDATA[<h3 id="HelloWorld-Python版"><a href="#HelloWorld-Python版" class="headerlink" title="HelloWorld(Python版)"></a>HelloWorld(Python版)</h3><h4 id="1-进入-ros-包添加-scripts-目录并编辑-python-文件"><a href="#1-进入-ros-包添加-scripts-目录并编辑-python-文件" class="headerlink" title="1.进入 ros 包添加 scripts 目录并编辑 python 文件"></a>1.进入 ros 包添加 scripts 目录并编辑 python 文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> ros包<br><span class="hljs-built_in">mkdir</span> scripts<br></code></pre></td></tr></table></figure><p>新建 python 文件: (文件名自定义)</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment">#! /usr/bin/env python</span><br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Python 版 HelloWorld</span><br><span class="hljs-string"></span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-keyword">import</span> rospy<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    rospy.init_node(<span class="hljs-string">&quot;Hello&quot;</span>)<br>    rospy.loginfo(<span class="hljs-string">&quot;Hello World!!!!&quot;</span>)<br></code></pre></td></tr></table></figure><h4 id="2-为-python-文件添加可执行权限"><a href="#2-为-python-文件添加可执行权限" class="headerlink" title="2.为 python 文件添加可执行权限"></a>2.为 python 文件添加可执行权限</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">chmod</span> +x 自定义文件名.py<br></code></pre></td></tr></table></figure><h4 id="3-编辑-ros-包下的-CamkeList-txt-文件"><a href="#3-编辑-ros-包下的-CamkeList-txt-文件" class="headerlink" title="3.编辑 ros 包下的 CamkeList.txt 文件"></a>3.编辑 ros 包下的 CamkeList.txt 文件</h4><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-built_in">catkin_install_python</span>(PROGRAMS scripts/自定义文件名.py<br>  DESTINATION $&#123;CATKIN_PACKAGE_BIN_DESTINATION&#125;<br>  )<br></code></pre></td></tr></table></figure><h4 id="4-进入工作空间目录并编译"><a href="#4-进入工作空间目录并编译" class="headerlink" title="4.进入工作空间目录并编译"></a>4.进入工作空间目录并编译</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> 自定义空间名称<br>catkin_make<br></code></pre></td></tr></table></figure><h4 id="5-进入工作空间目录并执行"><a href="#5-进入工作空间目录并执行" class="headerlink" title="5.进入工作空间目录并执行"></a>5.进入工作空间目录并执行</h4><p><strong>先启动命令行1：</strong></p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">roscore</span><br></code></pre></td></tr></table></figure><p><strong>再启动命令行2：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> 工作空间<br><span class="hljs-built_in">source</span> ./devel/setup.bash<br>rosrun 包名 自定义文件名.py            <br></code></pre></td></tr></table></figure><p>输出结果:<code>Hello World!!!!</code></p>]]></content>
    
    
    <categories>
      
      <category>tutorial</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ROS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>git的部分命令用法 --补充</title>
    <link href="/2024/01/08/git%E7%9A%84%E9%83%A8%E5%88%86%E5%91%BD%E4%BB%A4%E7%94%A8%E6%B3%95/"/>
    <url>/2024/01/08/git%E7%9A%84%E9%83%A8%E5%88%86%E5%91%BD%E4%BB%A4%E7%94%A8%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h3 id="git的部分命令用法-–补充"><a href="#git的部分命令用法-–补充" class="headerlink" title="git的部分命令用法 –补充"></a>git的部分命令用法 –补充</h3><ul><li>第一次上传内容到新的仓库</li></ul><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cmd">git init<br>git add . <br>git commit -m &quot;first commit&quot;<br>git remote add origin https://github.com/memory009/xx.git<br>git branch -M main<br>git push -u origin main<br></code></pre></td></tr></table></figure><ul><li>本地与仓库中内容存在差异</li></ul><blockquote><p>将仓库中存在且本地不存在的东西拉取下来，实现本地和仓库同步</p></blockquote> <figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmd">git pull<br></code></pre></td></tr></table></figure><ul><li><code>git add .</code>的时候错误将超过100M的大文件add进去，且进行了<code>git commit</code>操作<ul><li>由于每次commit都会存有缓存，所以需要将commit回退到之前的commit中</li><li>首先通过<code>git log</code>查看commit的时候产生的哈希值</li></ul></li></ul> <figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs cmd"># &lt;commit-hash&gt; 处填哈希值<br>git reset --hard &lt;commit-hash&gt;<br></code></pre></td></tr></table></figure><blockquote><p>注：–hard操作会回退到上次commit的状态，如果期间修改了代码，需要先备份一下，此操作不可逆，且会使用旧版本的覆盖新版本</p></blockquote><ul><li>使用<code>git starus</code>查看此时commit的状态，如果不通过则显示红色，如果通过部分则显示绿色，确定通过之后再<code>git push</code>就不会出错</li><li>github仓库中由于<code>.gitignore</code>添加时间较晚或者漏添加导致不想传上去的文件传上去了</li></ul><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs cmd">git rm -r --cached my_folder<br>git commit -m &quot;Stop tracking my_folder&quot;<br>git push origin main<br></code></pre></td></tr></table></figure><blockquote><p>此操作可以删掉远程仓库中的文件夹，同时不会删除本地的文件</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>tutorial</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>How to fix any computer</title>
    <link href="/2023/12/01/How-to-fix-any-computer/"/>
    <url>/2023/12/01/How-to-fix-any-computer/</url>
    
    <content type="html"><![CDATA[<p><img src="/img/figure/header.png" alt="header"></p><p><img src="/img/figure/windows.png" alt="header"></p><p><img src="/img/figure/linux.png" alt="header"></p><p><img src="/img/figure/apple.png" alt="header"></p>]]></content>
    
    
    
    <tags>
      
      <tag>joke</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Comparison of Autonomous Driving Simulator</title>
    <link href="/2023/10/12/Use%20and%20comparison%20of%20Autonomous%20driving%20simulator/"/>
    <url>/2023/10/12/Use%20and%20comparison%20of%20Autonomous%20driving%20simulator/</url>
    
    <content type="html"><![CDATA[<h1 id="Comparison-of-Autonomous-Driving-Simulator"><a href="#Comparison-of-Autonomous-Driving-Simulator" class="headerlink" title="Comparison of Autonomous Driving Simulator:"></a>Comparison of Autonomous Driving Simulator:</h1><h2 id="CARLA"><a href="#CARLA" class="headerlink" title="CARLA:"></a>CARLA:</h2><ul><li>Compatibility: CARLA supports both ROS1 and ROS2 and provides corresponding ROS interfaces, making integration with ROS relatively easy.</li><li>Ease of use: CARLA offers rich documentation and example code, allowing users to get started quickly. It also has a visual interface for convenient setup and monitoring of simulation experiments.</li><li>Map data details: CARLA’s map data has high realism and details, including road signs, traffic lights, pedestrians, vehicles, and other elements, providing a more realistic simulation environment.</li></ul><p>  Pros: Strong realism, rich map details, good ROS compatibility.<br>  Cons: Higher computational resource requirements, relatively steep learning curve.</p><h2 id="BeamNG"><a href="#BeamNG" class="headerlink" title="BeamNG:"></a>BeamNG:</h2><ul><li>Compatibility: BeamNG primarily supports ROS1, with relatively weaker support for ROS2.</li><li>Ease of use: BeamNG has an intuitive user interface and an easy-to-use editor, allowing users to create and modify scenes conveniently. It also provides a Python API for integration with ROS.</li><li>Map data details: BeamNG’s map data is relatively simple, focusing mainly on vehicle physics simulation and collision detection, potentially lacking in detail-oriented simulation.</li></ul><p>  Pros: Accurate physics simulation, ease of use and scene editing.<br>  Cons: Relatively simple map details, incomplete support for ROS2.</p><h2 id="LGSVL"><a href="#LGSVL" class="headerlink" title="LGSVL:"></a>LGSVL:</h2><ul><li>Compatibility: LGSVL supports both ROS1 and ROS2 and provides ROS interfaces for easy integration with ROS.</li><li>Ease of use: LGSVL has a user-friendly interface and interactive tools, making it easy to create and edit scenes. It also offers Python and C++ APIs for user customization and development.</li><li>Map data details: LGSVL’s map data is relatively detailed, supporting high-precision maps and real-world road networks, providing a more realistic simulation environment.</li></ul><p>  Pros: Ease of use and scene editing, rich map data details, good ROS compatibility.<br>  Cons: Higher computational resource requirements.</p><h2 id="Emphasis-of-different-simulators"><a href="#Emphasis-of-different-simulators" class="headerlink" title="Emphasis of different simulators:"></a>Emphasis of different simulators:</h2><ul><li>CARLA focuses on providing a highly realistic simulation environment with rich map details. It also excels in ROS compatibility, although the actual usage of ROS in CARLA may not be particularly user-friendly.</li><li>BeamNG emphasizes vehicle physics simulation and collision detection, suitable for in-depth research on vehicle behavior and physical characteristics.</li><li>LGSVL focuses on providing an easy-to-use interface and interactive tools, as well as high-precision map data, suitable for rapid prototyping and testing of autonomous driving algorithms.</li></ul>]]></content>
    
    
    <categories>
      
      <category>notebook</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Autopilot</tag>
      
      <tag>simulator</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ChatGPT 部署到个人域名，实现国内直接访问</title>
    <link href="/2023/10/10/ChatGPT-%20NEXT/"/>
    <url>/2023/10/10/ChatGPT-%20NEXT/</url>
    
    <content type="html"><![CDATA[<h1 id="ChatGPT-NEXT-部署到个人域名-tutorial"><a href="#ChatGPT-NEXT-部署到个人域名-tutorial" class="headerlink" title="ChatGPT-NEXT 部署到个人域名 - tutorial"></a>ChatGPT-NEXT 部署到个人域名 - tutorial</h1><blockquote><p>​此教程使用ChatGPT-NEXT（简单理解为通过ChatGPT的API服务，将问的问题转发到ChatGPT，实现在个人域名下体验大部分ChatGPT服务）提供的教程，使用免费服务器<code>vercel</code>部署ChatGPT，使个人域名通过DNS（Domain Name System），将ChatGPT-NEXT映射到自己的个人域名的子域名下。</p></blockquote><p>​&#x3D;&#x3D;达到在国内访问ChatGPT-NEXT的目的。&#x3D;&#x3D;</p><blockquote><p>​这个方案配置的优势在于：</p><pre><code class="hljs">- 更方便：使用个人域名访问，不需要“科学上网”- 更安全：配置好之后，可以通过加入密码的方式，防止个人域名遭到DDOS攻击- 更便捷：方便分享给家人好友使用，只需要OpenAI秘钥没有额度的时候进行额度充值- 更低成本：成本极低（域名 + OpenAI秘钥 &lt; 30RMB）</code></pre></blockquote><blockquote><p> 话不多说，先上效果图<br><img src="/img/figure/chat_demo.png" alt="demo"></p></blockquote><h2 id="在-Github中fork-ChatGPT-Next-Web"><a href="#在-Github中fork-ChatGPT-Next-Web" class="headerlink" title="在 Github中fork  ChatGPT-Next-Web"></a>在 Github中fork  <a href="https://github.com/Yidadaa/ChatGPT-Next-Web">ChatGPT-Next-Web</a></h2><blockquote><p> ChatGPT-Next-Web的优势</p></blockquote><ul><li><p><strong>Deploy for free with one-click</strong> on Vercel in under 1 minute</p></li><li><p>Compact client (~5MB) on Linux&#x2F;Windows&#x2F;MacOS, <a href="https://github.com/Yidadaa/ChatGPT-Next-Web/releases">download it now</a></p></li><li><p>Fully compatible with self-deployed llms, recommended for use with <a href="https://github.com/josStorer/RWKV-Runner">RWKV-Runner</a> or <a href="https://github.com/go-skynet/LocalAI">LocalAI</a></p></li><li><p>Privacy first, all data stored locally in the browser</p></li><li><p>Markdown support: LaTex, mermaid, code highlight, etc.</p></li><li><p>Responsive design, dark mode and PWA</p></li><li><p>Fast first screen loading speed (~100kb), support streaming response</p></li><li><p>New in v2: create, share and debug your chat tools with prompt templates (mask)</p></li><li><p>Awesome prompts powered by <a href="https://github.com/PlexPt/awesome-chatgpt-prompts-zh">awesome-chatgpt-prompts-zh</a> and <a href="https://github.com/f/awesome-chatgpt-prompts">awesome-chatgpt-prompts</a></p></li><li><p>Automatically compresses chat history to support long conversations while also saving your tokens</p></li><li><p>I18n: English, 简体中文, 繁体中文, 日本語, Français, Español, Italiano, Türkçe, Deutsch, Tiếng Việt, Русский, Čeština, 한국어, Indonesia</p></li><li><p>按照README.md的内容deploy到自己的仓库，并开启自动更新(由于官方讲的非常清楚，以下不做赘述)</p></li></ul><h2 id="购买一个个人域名-申请一个个人域名："><a href="#购买一个个人域名-申请一个个人域名：" class="headerlink" title="购买一个个人域名&#x2F;申请一个个人域名："></a>购买一个个人域名&#x2F;申请一个个人域名：</h2><ul><li><p><input checked="" disabled="" type="checkbox"> 在<a href="https://www.godaddy.com/">goddy</a>直接买一个</p><ul><li><p>建议直接整<code>.xyz</code>,<code>.lol</code>之类的域名，比较便宜，十几块钱一年是正常价格，太贵也没必要</p></li><li><p>申请完成后，使用goddy自带的DNS服务或者<a href="#choice">其他DNS服务</a>对域名进行配置</p></li></ul></li><li><p><input disabled="" type="checkbox"> 阿里云&#x2F;腾讯云申请一个（比较麻烦，并且需要实名制）</p></li></ul><h2 id="在vercel中添加个人域名，具体步骤如下："><a href="#在vercel中添加个人域名，具体步骤如下：" class="headerlink" title="在vercel中添加个人域名，具体步骤如下："></a>在<a href="https://vercel.com/memory009">vercel</a>中添加个人域名，具体步骤如下：</h2><ul><li><p>Settings</p></li><li><p>Domains</p></li><li><p>Add</p></li><li><p>输入域名</p></li><li><p><img src="/img/figure/vercel.png" alt="image-20230527002240186"></p></li><li><p><code>type</code>选择<code>CNAME</code>，<code>Name</code>可以自己命名，此处Name为子域名，只要不和其他Name重复即可，<code>Value</code>中的值需要记下来，之后要填到DNS的值的位置</p></li></ul><h2 id="购买-注册OpenAI账号"><a href="#购买-注册OpenAI账号" class="headerlink" title="购买&#x2F;注册OpenAI账号"></a>购买&#x2F;注册OpenAI账号</h2><ul><li><p>这个网上很多方法，我不好推荐</p></li><li><p>一个OpenAI账号大概有三个月有效期的免费额度，过期之后需要配置秘钥，以下是在<code>vercel</code>更换秘钥，并重新部署的方法</p><ul><li>进入<a href="https://vercel.com/memory009">vercel</a></li><li>chat-gpt-next-web</li><li>Settings</li><li>Environment Variables</li><li>edit</li><li>修改秘钥</li><li>切换到<code>Deployments</code>标签，redeploy你的vercel服务器，注：每次更新秘钥或者密码都需要手动redeploy，使vercel新的配置生效</li></ul></li></ul><h2 id="添加DNS信息"><a href="#添加DNS信息" class="headerlink" title="添加DNS信息"></a>添加DNS信息</h2><ul><li>如果使用的是godaddy的DNS服务，则添加DNS信息，使得vercel和域名信息保持一致，这样做的目的是为了让访问个人域名的时候，服务器会将你的域名指向vercel的位置，达到不适用VPN访问外网的效果</li></ul><p><img src="/img/figure/godaddy_2.png" alt="image-20230527023639457"></p><ul><li>注意:首次注册的域名需要先广播到全球，这可能需要几个小时的时间</li></ul><p><a name="choice"></a></p><h2 id="使用CDN加速服务-可选"><a href="#使用CDN加速服务-可选" class="headerlink" title="使用CDN加速服务(可选)"></a>使用CDN加速服务(可选)</h2><blockquote><p>目前貌似有不法分子用<code>vercel</code>来搞非法的东西，vercel 的IP是不是会被国内ban掉，以下方法使用<a href="https://dash.cloudflare.com/">cloudflare</a>对DNS进行管理，启用Proxy服务（说人话就是代理服务），使国内能通过CDN的优势，访问到</p></blockquote><ul><li><p>CDN服务是什么？</p><ul><li>CDN（内容分发网络）是一种网络服务，旨在通过将内容分发到全球各地的服务器节点上，提供快速、高效的内容传输和交付。CDN的目标是在用户请求内容时，从距离用户最近的服务器节点提供内容，以减少延迟和提高性能。</li><li>CDN通过在全球各地建立分布式的服务器节点，将内容缓存到这些节点上。当用户请求访问特定的内容时，CDN会自动将内容从最近的服务器节点传送给用户，而不需要从原始服务器上获取内容。这样可以大大减少网络延迟和带宽消耗，提高用户访问网站或应用程序的速度和质量。</li></ul></li><li><p>CDN服务有什么优势，为什么要用它？</p><ul><li><p>加速内容传输：通过就近提供内容，减少了网络延迟，提高了内容传输速度。</p></li><li><p>节省带宽成本：CDN可以缓存和提供静态内容，减少了原始服务器的负载和带宽消耗。</p></li><li><p>提高可靠性和稳定性：CDN通过分布式架构和冗余备份，提供了更高的可用性和容错性。</p></li><li><p>抵御分布式拒绝服务（DDoS）攻击：CDN可以通过分散流量和提供防护措施来帮助抵御DDoS攻击。</p></li></ul></li></ul><p>解释完CDN服务的概念之后，以下是使用cloudflare配置DNS的教程</p><ul><li>将Nameservers修改为Cloudflare Nameservers<ul><li><p>关掉原来在godaddy上的DNS服务</p></li><li><p>将godaddy上的Nameservers替换为Cloudflare提供的Nameservers</p></li><li><p>将原本的DNS配置全部复制到Cloudflare上即可</p></li></ul></li></ul><p><img src="/img/figure/Cloudflare.png" alt="image-20230527023639457"></p>]]></content>
    
    
    <categories>
      
      <category>tutorial</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ChatGPT</tag>
      
      <tag>domains</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CARLA-installation (for windows)</title>
    <link href="/2023/10/10/CARLA-installation-(for-windows)/"/>
    <url>/2023/10/10/CARLA-installation-(for-windows)/</url>
    
    <content type="html"><![CDATA[<h1 id="CARLA-installation-for-windows"><a href="#CARLA-installation-for-windows" class="headerlink" title="CARLA-installation (for windows)"></a>CARLA-installation (for windows)</h1><h2 id="Thanks-for-Mr-Wu-Sihao-and-Mr-Li-Renjue’s-contribution-to-this-installation-tutorial"><a href="#Thanks-for-Mr-Wu-Sihao-and-Mr-Li-Renjue’s-contribution-to-this-installation-tutorial" class="headerlink" title="Thanks for Mr. Wu Sihao and Mr. Li Renjue’s contribution to this installation tutorial!"></a>Thanks for <a href="https://github.com/WilliamWu96">Mr. Wu Sihao</a> and Mr. Li Renjue’s contribution to this installation tutorial!</h2><p>Knowing that most people are not very familiar with the Linux system, but they want to try to get in touch with the field of autonomous driving, so I will share the method of installing carla under windows here, hoping to help some people who want to learn how to get started with carla but don’t know how to configure it.  </p><p><strong>I highly recommend you to use python&#x3D;3.7 if you want to use CARLA-0.9.13.</strong>  </p><p><strong>please pay attention，the version of CARLA-0.9.10 recommend us to use python&#x3D;3.6</strong></p><h2 id="Install-CARLA"><a href="#Install-CARLA" class="headerlink" title="Install CARLA"></a>Install CARLA</h2><h3 id="references"><a href="#references" class="headerlink" title="references:"></a>references:</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/WilliamWu96/</span>Carla_Installation<span class="hljs-comment">#desktop-version-installation</span><br>https:<span class="hljs-regexp">//</span>zhuanlan.zhihu.com<span class="hljs-regexp">/p/</span><span class="hljs-number">338927297</span><br>https:<span class="hljs-regexp">//</span>zhuanlan.zhihu.com<span class="hljs-regexp">/p/</span><span class="hljs-number">390143776</span><br></code></pre></td></tr></table></figure><h3 id="1-Install-CARLA-0-9-13-CARLA-0-9-10"><a href="#1-Install-CARLA-0-9-13-CARLA-0-9-10" class="headerlink" title="1.Install CARLA-0.9.13&#x2F;CARLA-0.9.10"></a>1.Install CARLA-0.9.13&#x2F;CARLA-0.9.10</h3><ul><li><a href="https://github.com/carla-simulator/carla/releases">https://github.com/carla-simulator/carla/releases</a> </li><li>chose [Windows] CARLA<your version>.zip and download it.</li></ul><h3 id="2-unzip-the-file"><a href="#2-unzip-the-file" class="headerlink" title="2.unzip the file"></a>2.unzip the file</h3><h3 id="3-Run-CarlaUESTC4-exe"><a href="#3-Run-CarlaUESTC4-exe" class="headerlink" title="3.Run CarlaUESTC4.exe"></a>3.Run CarlaUESTC4.exe</h3><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs vim">#if you want <span class="hljs-keyword">to</span> use carla-<span class="hljs-number">0.9</span>.<span class="hljs-number">10</span>,please use <span class="hljs-keyword">python</span>=<span class="hljs-number">3.6</span> instead <span class="hljs-keyword">python</span>=<span class="hljs-number">3.7</span><br>conda create -n carla <span class="hljs-keyword">python</span>=<span class="hljs-number">3.7</span><br>conda activate carla<br><span class="hljs-keyword">cd</span> ~/PythonAPI/examples<br><span class="hljs-keyword">python</span> automatic_control.<span class="hljs-keyword">py</span><br></code></pre></td></tr></table></figure><h2 id="Issure"><a href="#Issure" class="headerlink" title="Issure"></a>Issure</h2><ul><li>If your terminal show that <code>no module named numpy</code>or<code>no module named shapely</code>or<code>no module named pygame</code> , please install them using pip:<figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">pip <span class="hljs-keyword">install </span>numpy<br>pip <span class="hljs-keyword">install </span><span class="hljs-keyword">shapely</span><br><span class="hljs-keyword"></span>pip <span class="hljs-keyword">install </span>pygame<br></code></pre></td></tr></table></figure></li><li>If your terminal show that  <code>no module named carla</code> , please:<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">cd</span> ~/PythonAPI/carla/dist<br><span class="hljs-comment">#if you use carla-0.9.10,you will find a similar .whl named carla-0.9.10-cp36-cp36m-win_amd64.whl</span><br><span class="hljs-attribute">pip</span> install carla-<span class="hljs-number">0</span>.<span class="hljs-number">9</span>.<span class="hljs-number">13</span>-cp37-cp37m-win_amd64.whl<br></code></pre></td></tr></table></figure></li></ul><h2 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h2><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs vim">#if you prefer <span class="hljs-keyword">to</span> use carla-<span class="hljs-number">0.9</span>.<span class="hljs-number">10</span>,please use <span class="hljs-keyword">python</span>=<span class="hljs-number">3.6</span> instead <span class="hljs-keyword">python</span>=<span class="hljs-number">3.7</span><br>conda create -n carla <span class="hljs-keyword">python</span>=<span class="hljs-number">3.7</span><br>conda activate carla<br><span class="hljs-keyword">cd</span> ~/PythonAPI/examples<br><span class="hljs-keyword">python</span> automatic_control.<span class="hljs-keyword">py</span><br></code></pre></td></tr></table></figure><ul><li>If you see a window named pygame like this picture , you have fully installed carla environment！！<br><a href="https://pic3.zhimg.com/v2-7e4f82bba4c5f6bcf3a96736dfac77c2_b.jpg">CARLA example</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>tutorial</category>
      
      <category>Environment configuration</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CARLA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ISS_SLAM_TUTORIAL</title>
    <link href="/2023/10/09/ISS_SLAM_TUTORIAL/"/>
    <url>/2023/10/09/ISS_SLAM_TUTORIAL/</url>
    
    <content type="html"><![CDATA[<h3 id="ISS-SLAM-TUTORIAL"><a href="#ISS-SLAM-TUTORIAL" class="headerlink" title="ISS_SLAM_TUTORIAL"></a>ISS_SLAM_TUTORIAL</h3><h4 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h4><h5 id="Mapping"><a href="#Mapping" class="headerlink" title="Mapping"></a>Mapping</h5><ol><li>Connect to ISS self-driving car through ssh using vscode</li></ol><ul><li><p>Step1:<br>Create a new terminal(ctrl+alt+t), then type <code>code .</code></p></li><li><p>Step2:</p><ul><li>Open Remote Explorer</li><li>Open new folder</li><li>Choice yahboom_ws</li><li>Create a new terminal in vscode through<code>roslaunch yahboomcar_nav 3d_laser_astrapro_bringup_and_slam.launch </code></li><li>Wait 15s</li><li><img src="/img/figure/ISS_SLAM_TUTORIAL_1.png" alt="image-20230511163034203"></li></ul></li></ul><ol start="2"><li>Display rviz on the local terminal</li></ol><ul><li><p>step1: </p><ul><li>Create a new terminal(ctrl+shift+&#96;)in vscode</li></ul></li><li><p>step2:</p><ul><li><code>cd Documents/yahboomcar_ws</code></li><li><code>source devel/setup.bash</code></li><li><code>roslaunch yahboomcar_nav view_cartographer.launch</code></li></ul></li><li><p>step3:</p><ul><li><p>Mapping with the remote</p></li><li><p><img src="/img/figure/ISS_SLAM_TUTORIAL_2.png" alt="image-20230511163103365"></p></li></ul></li></ul><p>———shut down all terminal———</p><h5 id="Navigation"><a href="#Navigation" class="headerlink" title="Navigation"></a>Navigation</h5><ol><li>Connect to ISS self-driving car through ssh using vscode</li></ol><ul><li><p>Step1:<br>Create a new terminal(ctrl+alt+t), then type <code>code .</code></p></li><li><p>Step2:</p><ul><li>Open Remote Explorer</li><li>Open new folder</li><li>Choice yahboom_ws</li><li>Create a new terminal in vscode through<code>roslaunch yahboomcar_nav 3d_laser_astrapro_bringup_and_navigation.launch </code></li><li>Wait 15s</li></ul></li></ul><ol start="2"><li>Display rviz on the local terminal</li></ol><ul><li>step1: <ul><li>Create a new terminal(ctrl+shift+&#96;)in vscode</li></ul></li><li>step2:<ul><li><code>cd Documents/yahboomcar_ws</code></li><li><code>source devel/setup.bash</code></li><li><code>roslaunch yahboomcar_nav view_cartographer.launch</code></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>tutorial</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Autopilot</tag>
      
      <tag>ROS</tag>
      
      <tag>SLAM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LIO-SAM environment configuration(Linux 20.04; ROS Noetic)</title>
    <link href="/2023/10/09/LIO-SAM/"/>
    <url>/2023/10/09/LIO-SAM/</url>
    
    <content type="html"><![CDATA[<h1 id="LIO-SAM-environment-configuration-Linux-20-04-ROS-Noetic"><a href="#LIO-SAM-environment-configuration-Linux-20-04-ROS-Noetic" class="headerlink" title="LIO-SAM environment configuration(Linux 20.04; ROS Noetic)"></a>LIO-SAM environment configuration(Linux 20.04; ROS Noetic)</h1><ol><li><p>Make sure you have installed ROS completely</p></li><li><p>Install <code>gtsam</code> from official <a href="https://github.com/borglab/gtsam#wrappers">github</a></p></li></ol><blockquote><p>I am highly recommend you to install from Releases(The version I downloaded is <a href="https://github.com/borglab/gtsam/releases/tag/4.1.1">4.1.1</a>)</p></blockquote><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cmd"># <span class="hljs-built_in">cd</span> to address where you download gtsam<br>$ <span class="hljs-built_in">cd</span> ~/gtsam-<span class="hljs-number">4</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br>$ <span class="hljs-built_in">mkdir</span> build &amp;&amp; <span class="hljs-built_in">cd</span> build<br>$ cmake -DGTSAM_BUILD_WITH_MARCH_NATIVE=OFF -DGTSAM_USE_SYSTEM_EIGEN=ON ..<br>$ sudo make -j8<br>$ sudo make install<br></code></pre></td></tr></table></figure><ol start="3"><li>create workspace<figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cmd">$ <span class="hljs-built_in">mkdir</span> -p ~/catkin_ws/src<br>$ <span class="hljs-built_in">cd</span> ~/catkin_ws/src<br>$ git clone https://github.com/TixiaoShan/LIO-SAM.git<br>$ <span class="hljs-built_in">cd</span> ..<br>$ catkin_make<br></code></pre></td></tr></table></figure></li></ol><h1 id="problems-solutions"><a href="#problems-solutions" class="headerlink" title="problems&amp;solutions"></a>problems&amp;solutions</h1><p>Q1:</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmd">fatal error: opencv/cv.h: No such file or directory<br></code></pre></td></tr></table></figure><p>A1:</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmd"># ubuntu20.<span class="hljs-number">04</span> install opencv4.<span class="hljs-number">2</span> by default, so we should change ~/include/utility.h<br></code></pre></td></tr></table></figure><ul><li><p>step1:<br>use <code>#include &lt;opencv2/opencv.hpp&gt;</code> instead of <code>#include &lt;opencv/cv.h&gt;</code>  in <code>utility.h</code></p></li><li><p>step2:<br>move<code>#include &lt;pcl/kdtree/kdtree_flann.h&gt;</code>in front of <code>#include &lt;opencv2/opencv.hpp&gt;</code></p></li></ul><p>Q2:</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmd">/usr/include/pcl-<span class="hljs-number">1</span>.<span class="hljs-number">10</span>/pcl/pcl_config.h:<span class="hljs-number">7</span>:<span class="hljs-number">4</span>: error: #error PCL requires C++<span class="hljs-number">14</span> or above<br></code></pre></td></tr></table></figure><p>A2:<br>it mean that PCL 1.10 require C++14 or higher<br>open<code>CMakeLists.txt</code>,  change <code>set(CMAKE_CXX_FLAGS &quot;-std=c++11&quot;)</code>  to <code>set(CMAKE_CXX_FLAGS &quot;-std=c++14&quot;)</code></p><p>Q3:</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmd">error while loading shared libraries: libmetis-gtsam.so: cannot open shared object file<br></code></pre></td></tr></table></figure><p>A3:<br>after installing gtsam, you’d better run <code>sudo ldconfig</code>, in order to update link settings<br>then, init workspace, run <code>catkin_make</code>again</p>]]></content>
    
    
    <categories>
      
      <category>tutorial</category>
      
      <category>Environment configuration</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Autopilot</tag>
      
      <tag>ROS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MMDetection &amp; object detection方面的调研</title>
    <link href="/2023/10/08/MMDetection/"/>
    <url>/2023/10/08/MMDetection/</url>
    
    <content type="html"><![CDATA[<h2 id="MMDetection-2D"><a href="#MMDetection-2D" class="headerlink" title="MMDetection(2D)"></a>MMDetection(2D)</h2><p>MMDetection is an open source object detection toolbox based on PyTorch. It consists of:</p><ul><li>Training recipes for object detection and instance segmentation.</li><li>360+ pre-trained models to use for fine-tuning 微调 (or training afresh).</li><li>Dataset support for popular vision datasets such as COCO, Cityscapes, LVIS and PASCAL VOC.</li></ul><p><a href="https://paperswithcode.com/lib/mmdetection">https://paperswithcode.com/lib/mmdetection</a></p><table><thead><tr><th></th><th align="center">MODEL</th><th align="center">TRANING ON</th><th align="center">BOX AP</th><th align="center">INFERENCETIME</th><th>PAPER</th><th>YEAR</th></tr></thead><tbody><tr><td><img src="https://production-media.paperswithcode.com/models/Screen_Shot_2021-02-24_at_1.00.08_PM_JkHBLyY.png" alt="img"></td><td align="center"><a href="https://paperswithcode.com/lib/mmdetection/dynamic-r-cnn">Dynamic R-CNN</a></td><td align="center"><a href="https://paperswithcode.com/dataset/coco">COCO</a></td><td align="center">38.9</td><td align="center"></td><td></td><td>2020</td></tr><tr><td><img src="https://production-media.paperswithcode.com/models/Screen_Shot_2021-02-24_at_12.57.06_PM_O1JC9NU.png" alt="img"></td><td align="center"><a href="https://paperswithcode.com/lib/mmdetection/detr">DETR</a></td><td align="center"><a href="https://paperswithcode.com/dataset/coco">COCO</a></td><td align="center">40.1</td><td align="center"></td><td></td><td>2020</td></tr><tr><td><img src="https://production-media.paperswithcode.com/models/Screen_Shot_2021-02-24_at_1.30.37_PM_Be7ErEb.png" alt="img"></td><td align="center"><a href="https://paperswithcode.com/lib/mmdetection/groie">GRoIE</a></td><td align="center"><a href="https://paperswithcode.com/dataset/coco">COCO</a></td><td align="center">42.2</td><td align="center"></td><td></td><td>2020</td></tr><tr><td><img src="https://production-media.paperswithcode.com/models/FASTER-RCNN_WhjSRSs.png" alt="img"></td><td align="center"><a href="https://paperswithcode.com/lib/mmdetection/regnet">RegNet</a></td><td align="center"><a href="https://paperswithcode.com/dataset/coco">COCO</a></td><td align="center">43.1</td><td align="center"></td><td></td><td>2020</td></tr><tr><td><img src="https://production-media.paperswithcode.com/models/Screen_Shot_2021-02-24_at_2.25.41_PM_XDv3zNX.png" alt="img"></td><td align="center"><a href="https://paperswithcode.com/lib/mmdetection/paa">PAA</a></td><td align="center"><a href="https://paperswithcode.com/dataset/coco">COCO</a></td><td align="center">45.1</td><td align="center"></td><td></td><td>2020</td></tr><tr><td><img src="https://production-media.paperswithcode.com/models/Screen_Shot_2021-02-24_at_2.51.06_PM_TdvT9xn.png" alt="img"></td><td align="center"><a href="https://paperswithcode.com/lib/mmdetection/sparse-r-cnn">Sparse R-CNN</a></td><td align="center"><a href="https://paperswithcode.com/dataset/coco">COCO</a></td><td align="center">46.2</td><td align="center"></td><td></td><td>2020</td></tr><tr><td><img src="https://production-media.paperswithcode.com/methods/Screen_Shot_2020-06-06_at_12.30.12_PM.png" alt="img"></td><td align="center"><a href="https://paperswithcode.com/lib/mmdetection/resnest">ResNeSt</a></td><td align="center"><a href="https://paperswithcode.com/dataset/coco">COCO</a></td><td align="center">47.7</td><td align="center"></td><td></td><td>2020</td></tr><tr><td><img src="https://production-media.paperswithcode.com/models/Screen_Shot_2021-02-24_at_12.53.32_PM_GHe6eIp.png" alt="img"></td><td align="center"><a href="https://paperswithcode.com/lib/mmdetection/detectors">DetectoRS</a></td><td align="center"><a href="https://paperswithcode.com/dataset/coco">COCO</a></td><td align="center">49.1</td><td align="center"></td><td></td><td>2020</td></tr><tr><td><img src="https://production-media.paperswithcode.com/models/Screen_Shot_2021-02-24_at_3.03.28_PM_R0DaAzb.png" alt="img"></td><td align="center"><a href="https://paperswithcode.com/lib/mmdetection/vfnet">VFNet</a></td><td align="center"><a href="https://paperswithcode.com/dataset/coco">COCO</a></td><td align="center">50.4</td><td align="center"></td><td></td><td>2020</td></tr><tr><td><img src="https://production-media.paperswithcode.com/models/Screen_Shot_2021-02-24_at_1.23.54_PM_XwE0mAh.png" alt="img"></td><td align="center"><a href="https://paperswithcode.com/lib/mmdetection/generalized-focal-loss">Generalized Focal Loss</a></td><td align="center"><a href="https://paperswithcode.com/dataset/coco">COCO</a></td><td align="center">48.1</td><td align="center">0.0935</td><td></td><td>2020</td></tr></tbody></table><p><a href="https://github.com/open-mmlab/mmdetection3d">https://github.com/open-mmlab/mmdetection3d</a></p><p>[<img src="/img/figure/mmdet3d-logo.png" alt="mmdet3d-logo"></p><p><strong>OpenMMLab website</strong> <a href="https://openmmlab.com/"><em>HOT</em> </a>   <strong>OpenMMLab platform</strong> <a href="https://platform.openmmlab.com/"><em>TRY IT OUT</em></a></p><p><a href="https://mmdetection3d.readthedocs.io/en/latest/"><img src="https://camo.githubusercontent.com/d5d535f53f2cb047c2b4382b8fd3c2913519abad35badcd4f22bd45d174f450a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6c61746573742d626c7565" alt="docs"></a> <a href="https://github.com/open-mmlab/mmdetection3d/actions"><img src="https://github.com/open-mmlab/mmdetection3d/workflows/build/badge.svg" alt="badge"></a> <a href="https://codecov.io/gh/open-mmlab/mmdetection3d"><img src="https://camo.githubusercontent.com/9d9dd5bbee06fe143d72c2a2f1907aaf74c2a68c716fcaa52e3cbcb9f8677033/68747470733a2f2f636f6465636f762e696f2f67682f6f70656e2d6d6d6c61622f6d6d646574656374696f6e33642f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="codecov"></a> <a href="https://github.com/open-mmlab/mmdetection3d/blob/master/LICENSE"><img src="https://camo.githubusercontent.com/aa0f4ed735ed4dbdbbc25ab552ee5d61089224d21ba1c545d7c16e0fa94da8d8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6f70656e2d6d6d6c61622f6d6d646574656374696f6e33642e737667" alt="license"></a></p><h2 id="MMDetection3D"><a href="#MMDetection3D" class="headerlink" title="MMDetection3D"></a>MMDetection3D</h2><p>MMDetection3D is an open source object detection toolbox based on PyTorch, towards the next-generation platform for general 3D detection. It is a part of the OpenMMLab project developed by <a href="http://mmlab.ie.cuhk.edu.hk/">MMLab</a>.（支持分布式训练和推理；it supports distributed training and inference.）</p><p><img src="/img/figure/mmdet3d_outdoor_demo.gif" alt="demo image"></p><h3 id="Major-features"><a href="#Major-features" class="headerlink" title="Major features"></a>Major features</h3><ul><li><p><strong>Support multi-modality&#x2F;single-modality detectors out of box</strong></p><p>It directly supports multi-modality(多模态)&#x2F;single-modality(单模态) detectors including MVXNet, VoteNet, PointPillars, etc.</p></li><li><p><strong>Support indoor&#x2F;outdoor 3D detection out of box</strong></p><p>It directly supports popular indoor and outdoor 3D detection datasets, including ScanNet, SUNRGB-D, Waymo, nuScenes, Lyft, and KITTI. For nuScenes dataset, we also support <a href="https://github.com/open-mmlab/mmdetection3d/tree/latest/configs/nuimages">nuImages dataset</a>.</p></li><li><p><strong>Natural integration with 2D detection</strong></p><p>All the about <strong>300+ models, methods of 40+ papers</strong>, and modules supported in <a href="https://github.com/open-mmlab/mmdetection/blob/3.x/docs/en/model_zoo.md">MMDetection</a> can be trained or used in this codebase.</p></li><li><p><strong>High efficiency</strong></p><p>It trains faster than other codebases. The main results are as below. Details can be found in <a href="https://github.com/open-mmlab/mmdetection3d/blob/main/docs/en/notes/benchmarks.md">benchmark.md</a>. We compare the number of samples trained per second (the higher, the better). The models that are not supported by other codebases are marked by <code>✗</code>.</p><table><thead><tr><th>Methods</th><th>MMDetection3D</th><th><a href="https://github.com/open-mmlab/OpenPCDet">OpenPCDet</a></th><th><a href="https://github.com/facebookresearch/votenet">votenet</a></th><th><a href="https://github.com/poodarchu/Det3D">Det3D</a></th></tr></thead><tbody><tr><td>VoteNet</td><td>358</td><td>✗</td><td>77</td><td>✗</td></tr><tr><td>PointPillars-car</td><td>141</td><td>✗</td><td>✗</td><td>140</td></tr><tr><td>PointPillars-3class</td><td>107</td><td>44</td><td>✗</td><td>✗</td></tr><tr><td>SECOND</td><td>40</td><td>30</td><td>✗</td><td>✗</td></tr><tr><td>Part-A2</td><td>17</td><td>14</td><td>✗</td><td>✗</td></tr></tbody></table></li></ul><p>Like <a href="https://github.com/open-mmlab/mmdetection">MMDetection</a> and <a href="https://github.com/open-mmlab/mmcv">MMCV</a>, MMDetection3D can also be used as a library to support different projects on top of it.</p><h3 id="Benchmarks"><a href="#Benchmarks" class="headerlink" title="Benchmarks"></a>Benchmarks</h3><p>Here we benchmark the training and testing speed of models in MMDetection3D, with some other open source 3D detection codebases.</p><h4 id="Settings"><a href="#Settings" class="headerlink" title="Settings"></a>Settings</h4><ul><li>Hardwares: 8 NVIDIA Tesla V100 (32G) GPUs, Intel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz<br>Software: Python 3.7, CUDA 10.1, cuDNN 7.6.5, PyTorch 1.3, numba 0.48.0.</li><li>Model: Since all the other codebases implements different models, we compare the corresponding models including SECOND, PointPillars, Part-A2, and VoteNet with them separately.</li><li>Metrics: We use the average throughput in iterations of the entire training run and skip the first 50 iterations of each epoch to skip GPU warmup time.</li></ul><h4 id="Main-Results"><a href="#Main-Results" class="headerlink" title="Main Results"></a>Main Results</h4><p>We compare the training speed (samples&#x2F;s) with other codebases if they implement the similar models. The results are as below, <strong>the greater the numbers in the table, the faster of the training process</strong>. The models that are not supported by other codebases are marked by <code>×</code>.</p><table><thead><tr><th>Methods</th><th>MMDetection3D</th><th>OpenPCDet</th><th>votenet</th><th>Det3D</th></tr></thead><tbody><tr><td>VoteNet</td><td>358</td><td>×</td><td>77</td><td>×</td></tr><tr><td>PointPillars-car</td><td>141</td><td>×</td><td>×</td><td>140</td></tr><tr><td>PointPillars-3class</td><td>107</td><td>44</td><td>×</td><td>×</td></tr><tr><td>SECOND</td><td>40</td><td>30</td><td>×</td><td>×</td></tr><tr><td>Part-A2</td><td>17</td><td>14</td><td>×</td><td>×</td></tr></tbody></table><p>In summary, MMdetection is a toolbox for object detection, MMCV is a foundation library(基础库) for computer vision research that supports MMDetection, and MMDetection3D is an extension of MMDetection for 3D object detection and tracking.</p><p>总之，MMDetection是一个物体检测的工具箱，MMCV是一个支持MMDetection的计算机视觉研究的基础库，而MMDetection3D是MMDetection的扩展，用于3D物体检测和跟踪。</p><h3 id="Verify-the-installation"><a href="#Verify-the-installation" class="headerlink" title="Verify the installation"></a>Verify the installation</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># single-gpu testing</span><br>python tools/test.py <span class="hljs-variable">$&#123;CONFIG_FILE&#125;</span> <span class="hljs-variable">$&#123;CHECKPOINT_FILE&#125;</span> [--cfg-options test_evaluator.pklfile_prefix=<span class="hljs-variable">$&#123;RESULT_FILE&#125;</span>]  [--show] [--show-dir <span class="hljs-variable">$&#123;SHOW_DIR&#125;</span>]<br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># e.g.</span><br>python demo/pcd_demo.py demo/data/kitti/000008.bin pointpillars_hv_secfpn_8xb6-160e_kitti-3d-car.py hv_pointpillars_secfpn_6x8_160e_kitti-3d-car_20220331_134606-d42d15ed.pth --show<br></code></pre></td></tr></table></figure><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">python tools<span class="hljs-regexp">/test.py configs/</span>votenet<span class="hljs-regexp">/votenet_8xb8_scannet-3d.py checkpoints/</span>votenet_8x8_scannet-<span class="hljs-number">3</span>d-<span class="hljs-number">18</span>class_20200620_230238-<span class="hljs-number">2</span>cea9c3a.pth --show --show-dir .<span class="hljs-regexp">/data/</span>scannet/show_results<br></code></pre></td></tr></table></figure><ul><li><p><input disabled="" type="checkbox"> VoteNet </p></li><li><p><input checked="" disabled="" type="checkbox"> PointPillars</p></li><li><p><input disabled="" type="checkbox"> SECOND</p></li><li><p><input disabled="" type="checkbox"> Part-A2</p></li></ul><h3 id="雷达参数"><a href="#雷达参数" class="headerlink" title="雷达参数"></a>雷达参数</h3><blockquote><p>目前大车使用的镭神智能的雷达参数</p></blockquote><p><img src="https://pic1.zhimg.com/v2-c37643d43854f555e89cc3f3e5aae138_r.jpg" alt="img"></p><blockquote><p>测绘激光雷达三维测绘激光雷达 MS-C16</p></blockquote><table><thead><tr><th align="center">大场景快速建模</th><th align="center">近程高精建图</th></tr></thead><tbody><tr><td align="center"><img src="https://www.leishen-lidar.com/public/attachment/images/20210525/833cf8d7b65d2925469d07b584a1eee2.jpg" alt="img"></td><td align="center"><img src="https://www.leishen-lidar.com/public/attachment/images/20210525/ec827ed4b51ce3d2c38122cf071dcde5.jpg" alt="img"></td></tr></tbody></table><blockquote><p>镭神智能128 线混合固态激光雷达 CH128 效果</p></blockquote><table><thead><tr><th align="center">非机动车</th><th align="center">轿车</th></tr></thead><tbody><tr><td align="center"><img src="https://www.leishen-lidar.com/public/attachment/images/20210430/e8cddbf06dc62fd428b3c514568733c0.jpg" alt="img" style="zoom:25%;" /></td><td align="center"><img src="https://www.leishen-lidar.com/public/attachment/images/20210430/d375483090b6c825e5db230913d94b5c.jpg" alt="img" style="zoom:25%;" /></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>notebook</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Autopilot</tag>
      
      <tag>object detection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PointPillars 论文笔记</title>
    <link href="/2023/10/08/PointPillars/"/>
    <url>/2023/10/08/PointPillars/</url>
    
    <content type="html"><![CDATA[<h2 id="PointPillars"><a href="#PointPillars" class="headerlink" title="PointPillars"></a>PointPillars</h2><blockquote><p><a href="D:\中国科学院软件研究所\自动驾驶\相关文献\PointPillars.pdf">PointPillars.pdf</a> </p><p>PointPillar的网络结构</p><p>(D, P, N)–&gt; (C, P, N) –&gt; (C, P) –&gt; (C, H, W) –&gt; (6C, H&#x2F;2, W&#x2F;2) –&gt; bbox</p></blockquote><p><img src="/img/figure/pointpillars_1.png" alt="pointpillars_1"></p><ol><li>提出一种新的encoding points的方式: Pillar</li><li>fast version–  平均62Hz , faster version– 105 Hz, 超过SECOND三倍。(激光雷达工作频率通常是5HZ&#x2F;10HZ&#x2F;20Hz，105HZ的LIDAR现实中比较少)</li><li>对于模型能达到的速度和真实自动驾驶场景能达到的速度做了一些讨论</li></ol><ul><li><p>PointPillars-car:</p><p>PointPillars-car是专门用于检测汽车的模型，它只需要检测汽车这一种目标类别，因此输出结果只包含汽车的检测框和相关的属性信息</p></li><li><p>PointPillars-3class:</p><p>PointPillars-3class则可以检测三种目标类别，包括汽车、行人和自行车，因此输出结果会同时包含这三种目标的检测框和相关属性信息。</p></li></ul><h3 id="Pillar-方式编码"><a href="#Pillar-方式编码" class="headerlink" title="Pillar 方式编码"></a>Pillar 方式编码</h3><p><strong>(D, P, N)–&gt; (C, P, N) –&gt; (C, P) –&gt; (C, H, W) –&gt; (6C, H&#x2F;2, W&#x2F;2) –&gt; bbox</strong></p><p><strong>– 张量化</strong></p><p>point clouds –&gt; (D, P, N)</p><blockquote><p>p : max number of pillars (P)，最大pillars (P) 具体使用 12000<br>N : max number of points per pillar (N)，每个pillars的最大点数 (N), 具体使用100<br>D : 是 dimension</p><p>点云的表示(D&#x3D;9 dimension)：</p></blockquote><p>$$<br>(x,y,z,r,x_c,y_c,z_c,x_p,y_p)<br>$$</p><p>$$ x,y,z$$为点云的真实坐标信息和反射强度,$$x_c,y_c,z_c$$为该点云所处Pillar中的所有点的几何中心；$$x_p,y_p$$为$$x-x_c,y-y_c$$,反应了点与几何中心的相对位置。</p><p><img src="/img/figure/pointpillars_2.png" alt="pointpillars_2"></p><ul><li>特征提取网络：应用线性层(linear layer)，然后应用 BatchNorm 和 ReLU 以生成 (C, P, N) 大小的<br>张量。</li></ul><blockquote><p>原来的维度是D&#x3D;9，经过Pillar Feature Net（<strong>特征提取网络</strong>）后，得到新的维度C，(D, P, N) –&gt; (C, P, N）</p><p>按照Pillar所在维度进行Max Pooling操作，即获得了(C, P)维度的特征图。</p><p>特征被编码后，特征会被分散到原来的pillar的位置，创建一个尺寸为(C, H, W)，其中H和W表示画布的长度和高度。</p></blockquote><p><strong>– Backbone (2D CNN)</strong></p><ul><li>指在输入图像上进行特征提取的网络核心结构。</li><li>Backbone 通常由一系列卷积层组成，通常以分层结构组织，学习检测输入图像中越来越复杂和抽象的特征。然后，这些特征被传递给一个或多个执行分类任务的全连接层。</li><li>Backbone 结构的选择对网络的性能有很大的影响，包括准确性和计算效率方面。流行的二维CNN的骨干架构包括VGG、ResNet、Inception和MobileNet等。   </li><li>在许多情况下，骨干结构可以在一个大的数据集上进行预训练，如ImageNet，以学习一套通用的特征，这些特征可以为特定的任务进行微调。这种方法被称为迁移学习，在为特定的应用开发和训练一个新的CNN时可以节省大量的时间和计算资源。</li><li><img src="/img/figure/pointpillars_3.png" alt="pointpillars_3"></li><li>mmdetection3D中针对KITTi数据集使用的Backbone是SECFN，下面只放KITTI的结果，其他结果(nuScenes&#x2F;Lyft&#x2F;Waymo)详见<a href="https://github.com/open-mmlab/mmdetection3d/blob/main/configs/pointpillars/README.md">https://github.com/open-mmlab/mmdetection3d/blob/main/configs/pointpillars/README.md</a></li><li><h4 id="Results-and-models"><a href="#Results-and-models" class="headerlink" title="Results and models"></a>Results and models</h4><h5 id="KITTI"><a href="#KITTI" class="headerlink" title="KITTI"></a>KITTI</h5><table><thead><tr><th>Backbone</th><th>Class</th><th>Lr schd</th><th>Mem (GB)</th><th>Inf time (fps)</th><th>AP</th><th>Download</th></tr></thead><tbody><tr><td><a href="https://github.com/open-mmlab/mmdetection3d/blob/main/configs/pointpillars/pointpillars_hv_secfpn_8xb6-160e_kitti-3d-car.py">SECFPN</a></td><td>Car</td><td>cyclic 160e</td><td>5.4</td><td></td><td>77.6</td><td><a href="https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car_20220331_134606-d42d15ed.pth">model</a> | <a href="https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car/hv_pointpillars_secfpn_6x8_160e_kitti-3d-car_20220331_134606.log.json">log</a></td></tr><tr><td><a href="https://github.com/open-mmlab/mmdetection3d/blob/main/configs/pointpillars/pointpillars_hv_secfpn_8xb6-160e_kitti-3d-3class.py">SECFPN</a></td><td>3 Class</td><td>cyclic 160e</td><td>5.5</td><td></td><td>64.07</td><td><a href="https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class_20220301_150306-37dc2420.pth">model</a> | <a href="https://download.openmmlab.com/mmdetection3d/v1.0.0_models/pointpillars/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class/hv_pointpillars_secfpn_6x8_160e_kitti-3d-3class_20220301_150306.log.json">log</a></td></tr></tbody></table></li></ul><p> <strong>(C, H, W) –&gt; (6C, H&#x2F;2, W&#x2F;2)</strong></p><p><img src="/img/figure/pointpillars_4.png" alt="pointpillars_4"></p><ul><li><p>第一个网络：自上而下的网络以越来越小的空间分辨率产生特征，同时提升特征图的维度</p></li><li><p>第二个网络：对自上而下的特征进行上采样和串联。</p><p>之所以选择这样架构，是因为<strong>不同分辨率的特征图负责不同大小物体的检测</strong>。比如分辨率大的特征图往往感受野较小，适合捕捉小物体（在KITTI中就是行人）。</p></li></ul><p><strong>– Detection Head</strong></p><blockquote><p>文章中使用后Single Shot Detector（SSD）进行三维物体的检测设置，类似于SSD</p><ul><li>使用二维联合交集（IoU）将先验框和ground truth相匹配</li><li>boundingbox的高度H不用于匹配，相反给定一个二维的匹配，使高度和仰角成为额外的回归目标</li></ul></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 二维联合交集（IoU）的解释   </span><br>    在计算机视觉中，二维交叉联合可以用来进行目标检测、图像匹配、特征提取等任务。该方法将一个小的二维核（通常为正方形或矩形）在图像上滑动，计算核与图像重叠部分的像素值乘积的总和，得到一个输出矩阵。这个输出矩阵可以被解释为原始图像中与核最相似的区域。<br>    二维交叉联合可以用来检测图像中的边缘、纹理、角点等特征。在深度学习中，卷积神经网络（Convolutional Neural Network，CNN）中的卷积层实际上就是应用了二维交叉联合的操作。<br><span class="hljs-comment"># Conv是卷积convolutional的缩写，Deconv是去卷积操作</span><br>Conv layer常用于图像分类，物体检测和分割，这些层对输入数据进行卷积运算。<br>Deconv layer 被用于图像的生成和修复任务，进行反向的卷积操作，以便生成一个大于输入的输出，去卷积层通常也被称为转置的卷积层或者上采样层(upsampling)<br></code></pre></td></tr></table></figure><p><strong>Network</strong></p><p>$S$:相对于原始输入伪图像的测量值</p><ul><li><p>The encoder network jas C &#x3D; 64 output features, </p></li><li><p>First block (S &#x3D; 2 for car, S &#x3D; 1 for pedestrian&#x2F;cyclist).</p></li><li><p>Both network consists of three blocks, Block1(S, 4, C), Block2(2S, 6, 2C), and Block3(4S, 6, 4C).</p></li><li><p>three blocks,每个区块采用上采样步骤进行升采样，Up1(S, S, 2C), Up2(2S, S, 2C),  and Up3(4S, S, 2C),然后，三个区块被串联起来，形成Detection Head的6C特征</p></li></ul><p><strong>Loss funtion</strong></p><p>PointPillar use the same loss function  introduced in SECOND.</p><p>PointPillar的loss function和SECOND相似，每个3D的Boundingbox用一个7维的向量表示，分别为($x,y,z,w,h,l,\theta $),其中($x,y,z$)为中心，($w,h,l$)为尺寸数据，$\theta$为方向角。</p><p>检测框回归任务中要学习的参数维这7个变量的偏移量：<br>$\Delta x&#x3D;\frac{x^{gt}-x^{a}}{d^{a}}$；$\Delta y&#x3D;\frac{y^{gt}-y^{a}}{d^{a}}$；$\Delta z&#x3D;\frac{z^{gt}-z^{a}}{h^{a}}$；<br>$\Delta w&#x3D;log\frac{w^{gt}}{w^{a}}$$；\Delta l&#x3D;log\frac{l^{gt}}{l^{a}}$；$\Delta \theta&#x3D;sin(\theta^{gt}-\theta^{a})$</p><ul><li><p>$x^{gt}$:ground truth</p></li><li><p>$x^{a}$:anchor boxes(锚定框)</p></li><li><p>$d^{a}&#x3D;\sqrt{(w^{a})^{2}+(l^{a})^{2}} $</p></li></ul><p>$$<br>  L_loc&#x3D;\sum_{b\in (x,y,z,w,l,h,\theta)}SmoothL1(\Delta b)<br>$$</p><p>由于角度定位损失不能区分翻转的boxes，所以文章使用了一个关于离散化方向的softmax分类损失，$L_dir$(离散方向)，使得网络能够学习到heading的方向。</p><ul><li><p>对于object classification loss,使用focal loss:<br>$$<br>L_cls&#x3D;-\alpha_a(1-\beta^{a})^{\gamma}logp^{a}<br>$$</p></li><li><p>$p^{\alpha}$为锚点为某个类的可能性（置信度），其中$\alpha&#x3D;0.25$$\gamma&#x3D;2$，最终损失函数为：<br>$$<br>L&#x3D;\frac{1}{N_pos}(\beta_locL_loc+\beta_clsL_cls+\beta_dirL_dir)<br>$$</p></li><li><p>其中$N_pos$是positive anchors的数量，$\beta_los&#x3D;2$,$\beta_cls&#x3D;1$,$、beta_dir&#x3D;0.2$</p></li></ul><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><ul><li>PointPillar only train on lidar point clouds in KITTI dataset, but compare with fusion methods that use both lidar</li></ul>]]></content>
    
    
    <categories>
      
      <category>notebook</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Autopilot</tag>
      
      <tag>Adversarial Attack</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hexo部署到github.io中遇到的问题及解决方法</title>
    <link href="/2023/10/08/Hexo%E9%83%A8%E7%BD%B2%E5%88%B0github.io%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
    <url>/2023/10/08/Hexo%E9%83%A8%E7%BD%B2%E5%88%B0github.io%E4%B8%AD%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>解决<code>hexo -d </code>部署后与<code>github.io</code>不同步问题</p><blockquote><p>github.io中应避免出现两个及以上的branch，建议保留master</p></blockquote><p><code>hexo - d</code> 部署到<code>github.io</code> 时，hexo会根据<code>_config.yml</code>下的<code>Deployment</code>寻找github中的<code>branch</code>，多数教程中涉及在<code>Deployment</code>末尾加入<code>_config.yml</code>比如：</p><figure class="highlight plaintext"><figcaption><span>Deployment</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs #"># Deployment<br>## Docs: https://hexo.io/docs/one-command-deployment<br>deploy:<br>  type: git<br>  repo: https://github.com/memory009/memory009.github.io.git<br>  branch: master<br></code></pre></td></tr></table></figure><p>注意：</p><ul><li>此处添加的branch为<code>master</code>分支，最新的github将默认分支改为了<code>main</code>，所以在Git bash中进入blog目录之后使用<code>hexo deploy </code>部署是无效的</li></ul><p>解决办法：</p><ul><li>在github.io中<code>view all branches</code>, 将<code>main</code>分支删掉，将<code>master</code>分支设置为default(因为hexo出现的时间比较早，早期的github默认的主分支是<code>master</code>)</li><li>进入<code>settings</code> – &gt; <code>pages</code> 重新将根域名配置到 <code>Custom domain</code>, 等待几分钟后，根域名会通过<code>CNAME</code>指向github.io，实现在根域名直接看到github.io的效果</li></ul><p>测试方法：<br>在管理员权限下<code>Git bash</code>进入blog目录下</p><ul><li><code>$ hexo -clean </code>  : 清理缓存(慎用，会将blog&#x2F;public文件夹内全部东西恢复默认)</li><li><code>$ hexo generate </code>   : 生成静态网站</li><li><code>$ hexo -deploy</code> : 部署静态网站</li><li><code>$ hexo server  </code> : 在本地预览静态网站</li></ul>]]></content>
    
    
    <categories>
      
      <category>Environment configuration</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo</tag>
      
      <tag>github</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/10/07/hello-world/"/>
    <url>/2023/10/07/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
